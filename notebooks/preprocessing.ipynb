{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Load datasets\n",
    "car_dekho_df = pd.read_csv(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/raw/CAR DETAILS FROM CAR DEKHO.csv\")\n",
    "car_details_v4_df = pd.read_csv(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/raw/car details v4.csv\")\n",
    "car_prices_df = pd.read_csv(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/raw/car_prices.csv\")\n",
    "supply_chain_df = pd.read_csv(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/raw/Car_SupplyChainManagementDataSet.csv\")\n",
    "logistics_df = pd.read_excel(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/raw/Supply chain logisitcs problem.xlsx\", sheet_name=\"OrderList\")\n",
    "\n",
    "# Load metadata JSON\n",
    "with open(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/raw/archive (13)/Car damages dataset/meta.json\", \"r\") as f:\n",
    "    meta_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Preprocessing Completed! Merged dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Convert metadata into a DataFrame\n",
    "image_meta_df = pd.DataFrame(meta_data[\"classes\"])\n",
    "image_meta_df.rename(columns={\"title\": \"Part_Class\", \"id\": \"Defect_ID\"}, inplace=True)\n",
    "\n",
    "# ------------------ STEP 1: Handle Missing Values ------------------\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "for df in [car_dekho_df, car_details_v4_df, car_prices_df, supply_chain_df, logistics_df]:\n",
    "    df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with \"Unknown\"\n",
    "for df in [car_dekho_df, car_details_v4_df, car_prices_df, supply_chain_df, logistics_df]:\n",
    "    df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# ------------------ STEP 2: Feature Engineering ------------------\n",
    "\n",
    "# Convert Year into Car Age\n",
    "car_details_v4_df[\"Car_Age\"] = 2025 - car_details_v4_df[\"Year\"]\n",
    "\n",
    "# Normalize numerical values (Weight, Price, Odometer)\n",
    "scaler = MinMaxScaler()\n",
    "numerical_cols = [\"Price\", \"Kilometer\", \"CarPrice\", \"Weight\"]\n",
    "for col in numerical_cols:\n",
    "    if col in car_details_v4_df.columns:\n",
    "        car_details_v4_df[col] = scaler.fit_transform(car_details_v4_df[[col]])\n",
    "\n",
    "# Encode categorical columns\n",
    "encoder = LabelEncoder()\n",
    "categorical_cols = [\"Make\", \"Model\", \"Fuel Type\", \"Transmission\", \"Carrier\", \"Service Level\"]\n",
    "for col in categorical_cols:\n",
    "    if col in car_details_v4_df.columns:\n",
    "        car_details_v4_df[col] = encoder.fit_transform(car_details_v4_df[col])\n",
    "\n",
    "# ------------------ STEP 3: Fix Column Compatibility for Merging ------------------\n",
    "\n",
    "# Convert 'OrderID' and 'Order ID' to string to ensure compatibility\n",
    "supply_chain_df['OrderID'] = supply_chain_df['OrderID'].astype(str)\n",
    "logistics_df['Order ID'] = logistics_df['Order ID'].astype(str)\n",
    "\n",
    "# Use CarModel instead of ProductID for merging with car details\n",
    "supply_chain_df['CarModel'] = supply_chain_df['CarModel'].astype(str)\n",
    "car_details_v4_df['Model'] = car_details_v4_df['Model'].astype(str)\n",
    "\n",
    "# Convert ProductID to string for merging with metadata\n",
    "supply_chain_df['ProductID'] = supply_chain_df['ProductID'].astype(str)\n",
    "image_meta_df['Defect_ID'] = image_meta_df['Defect_ID'].astype(str)\n",
    "\n",
    "# ------------------ STEP 4: Merge Datasets ------------------\n",
    "\n",
    "# Merge supply chain data with logistics using OrderID\n",
    "merged_df = pd.merge(supply_chain_df, logistics_df, left_on=\"OrderID\", right_on=\"Order ID\", how=\"left\")\n",
    "\n",
    "# Merge with car details using CarModel instead of ProductID\n",
    "merged_df = pd.merge(merged_df, car_details_v4_df, left_on=\"CarModel\", right_on=\"Model\", how=\"left\")\n",
    "\n",
    "# Merge with image metadata using ProductID (assuming Defect_ID corresponds to ProductID)\n",
    "final_df = pd.merge(merged_df, image_meta_df, left_on=\"ProductID\", right_on=\"Defect_ID\", how=\"left\")\n",
    "\n",
    "# ------------------ STEP 5: Save Final Preprocessed Dataset ------------------\n",
    "\n",
    "# Drop unnecessary columns\n",
    "final_df.drop(columns=[\"Order ID\", \"Model\", \"Defect_ID\"], inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(\"/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/processed/final_preprocessed_data1.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data Preprocessing Completed! Merged dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Cleaning and Re-merging Completed! Cleaned dataset saved at /Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/processed/cleaned_final_preprocessed_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r5/_bzgrbtj6tg33lk21qcyg0l80000gn/T/ipykernel_21346/3006025990.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df[numerical_columns] = imputer.fit_transform(cleaned_df[numerical_columns])\n",
      "/var/folders/r5/_bzgrbtj6tg33lk21qcyg0l80000gn/T/ipykernel_21346/3006025990.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df[categorical_columns] = imputer_cat.fit_transform(cleaned_df[categorical_columns])\n",
      "/var/folders/r5/_bzgrbtj6tg33lk21qcyg0l80000gn/T/ipykernel_21346/3006025990.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df[col] = pd.to_datetime(cleaned_df[col], errors='coerce')\n",
      "/var/folders/r5/_bzgrbtj6tg33lk21qcyg0l80000gn/T/ipykernel_21346/3006025990.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df[col] = pd.to_datetime(cleaned_df[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "preprocessed_data_path = '/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/processed/final_preprocessed_data1.csv'\n",
    "preprocessed_df = pd.read_csv(preprocessed_data_path)\n",
    "\n",
    "# Load image metadata if needed\n",
    "# Assuming 'meta_data' is a dictionary containing the metadata information\n",
    "image_meta_df = pd.DataFrame(meta_data[\"classes\"])\n",
    "image_meta_df.rename(columns={\"title\": \"Part_Class\", \"id\": \"Defect_ID\"}, inplace=True)\n",
    "\n",
    "# ------------------ STEP 1: Re-Merge Missing Data ------------------\n",
    "\n",
    "# Convert necessary columns to string for merging\n",
    "preprocessed_df['ProductID'] = preprocessed_df['ProductID'].astype(str)\n",
    "image_meta_df['Defect_ID'] = image_meta_df['Defect_ID'].astype(str)\n",
    "\n",
    "# Re-merging image metadata using ProductID\n",
    "merged_df = pd.merge(preprocessed_df, image_meta_df, left_on=\"ProductID\", right_on=\"Defect_ID\", how=\"left\")\n",
    "\n",
    "# ------------------ STEP 2: Drop Columns with 100% Missing Values ------------------\n",
    "\n",
    "# Drop columns where all values are NaN\n",
    "cleaned_df = merged_df.dropna(axis=1, how='all')\n",
    "\n",
    "# ------------------ STEP 3: Handle Missing Values ------------------\n",
    "\n",
    "# Filling missing numerical values with median\n",
    "numerical_columns = cleaned_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "cleaned_df[numerical_columns] = imputer.fit_transform(cleaned_df[numerical_columns])\n",
    "\n",
    "# Filling missing categorical values with \"Unknown\"\n",
    "categorical_columns = cleaned_df.select_dtypes(include=['object']).columns\n",
    "imputer_cat = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "cleaned_df[categorical_columns] = imputer_cat.fit_transform(cleaned_df[categorical_columns])\n",
    "\n",
    "# ------------------ STEP 4: Convert Date Fields ------------------\n",
    "\n",
    "# Convert date fields to datetime format\n",
    "date_columns = ['OrderDate', 'ShipDate']\n",
    "for col in date_columns:\n",
    "    if col in cleaned_df.columns:\n",
    "        cleaned_df[col] = pd.to_datetime(cleaned_df[col], errors='coerce')\n",
    "\n",
    "# ------------------ STEP 5: Save the Cleaned Dataset ------------------\n",
    "\n",
    "# Save the cleaned and merged dataset\n",
    "cleaned_data_path = '/Users/adityasrivatsav/Documents/GitHub/-SmartStock-AI-powered-inventory-optimization-and-demand-forecasting/data/processed/cleaned_final_preprocessed_data.csv'\n",
    "cleaned_df.to_csv(cleaned_data_path, index=False)\n",
    "\n",
    "print(f\"✅ Data Cleaning and Re-merging Completed! Cleaned dataset saved at {cleaned_data_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
